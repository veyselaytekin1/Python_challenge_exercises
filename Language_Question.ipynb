{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lang1\n"
     ]
    }
   ],
   "source": [
    "# Data Engineering - Interview Question - 2nd techical interview\n",
    "\n",
    "# Write a function that, for a string phrase as an argument, returns a string that indicates the language to which this phrase belongs.\n",
    "# If you can't determine the language or an error occurs - your function should return unknown.\n",
    "\n",
    "# Note:\n",
    "\n",
    "# Please avoid using any libraries or functions (langdetect, Polyglot, etc.) for detecting a language.\n",
    "# The task is about you writing an algorithm based on the input data and dataset you have.\n",
    "# We are looking for a clean and efficient solution: when you are done\n",
    "\n",
    "lang_dataset = {\n",
    "        \"lang1\": \"The gladdest moment in life is a departure into unknown lands. Travel makes one modest. You see what a tiny place you occupy in the world. Better to see something once than hear about it a thousand times.\",\n",
    "        \"lang2\": \"İnsan hayatındaki en mutlu an, bilinmeyen topraklara doğru yola çıkmaktır. Seyahat bir mütevazı yapar. Dünyada ne kadar küçük bir yer işgal ett\",\n",
    "        \"lang3\": \"Радісний момент у житті людини це опинитися на невідомих землях. Подорож робить тебе скромним. Ти бачиш, яке маленьке місце займаєш у світі. Краще побачити щось один раз, ніж почути про це тисячу разів.\"\n",
    "}\n",
    "\n",
    "lang_dataset[\"lang1\"].lower()  #bu islemler ile yukardaki dict'teki kelimeleri kücük harf yaptim\n",
    "lang_dataset[\"lang2\"].lower()\n",
    "lang_dataset[\"lang3\"].lower()\n",
    "\n",
    "phrase = \"This Is happy Life\"\n",
    "phrase2 = \"insan en mutlu life \"\n",
    "\n",
    "\n",
    "phrase = phrase.lower()\n",
    "phrase = phrase.split(' ')\n",
    "dct_score ={}   # I created that, to see how many points each languages got.\n",
    "\n",
    "for lang,sentence in lang_dataset.items():   # with that I get the items of dictionary\n",
    "    score=0      # I put that hier, in every circle it it reset yourself\n",
    "    for word in phrase:\n",
    "        if word in sentence:\n",
    "            score+=1\n",
    "    dct_score[lang] = score\n",
    "\n",
    "max_score = max(dct_score.values())   #I get the max values from languages\n",
    "\n",
    "max_lang = max(dct_score, key = dct_score.get)  #with that i get the key of the max values\n",
    "\n",
    "if max_score ==0:\n",
    "        print('no language') \n",
    "else:\n",
    "        print(max_lang)         \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
